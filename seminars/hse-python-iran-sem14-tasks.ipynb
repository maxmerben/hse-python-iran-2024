{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea17432-ea86-4cb1-bed1-bdd795b70aa0",
   "metadata": {},
   "source": [
    "# Дополнительные задачи №14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ab864-f3a9-4dfd-8483-d90174c727f1",
   "metadata": {},
   "source": [
    "## Задача 14. Самые-самые жесть важные слова"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcbf25-7677-4eae-8c8c-241c19aa820a",
   "metadata": {},
   "source": [
    "В этом задании вам предстоит поработать с небольшим корпусом текстов классической русской прозы, векторизовать их с помощью TF-IDF и по получившимся векторам ответить на несколько вопросов по содержанию текстов. Вот эти тексты:\n",
    "- «**История Пугачёва**», Александр Пушкин (1834) [**[ссылка](https://github.com/maxmerben/hse-python-iran-2024/blob/main/other/sem14-pushkin-istoria_pugacheva.txt)**]\n",
    "- «**Война и мир**», Лев Толстой (1865–1869), тома I–II [**[ссылка](https://github.com/maxmerben/hse-python-iran-2024/blob/main/other/sem14-tolstoy-voyna_i_mir.txt)**]\n",
    "- «**Жизнь Клима Самгина**», Максим Горький (1925–1936, незавершённый роман) [**[ссылка](https://github.com/maxmerben/hse-python-iran-2024/blob/main/other/sem14-gorkiy-zhizn_klima_samgina.txt)**]\n",
    "\n",
    "Скачайте *txt*-файлы с текстами и положите их в ту же папку, где находится эта тетрадка.\n",
    "\n",
    "Для выполнения задания вам понадобятся библиотеки и модули `nltk`, `pymorphy3`, `sklearn` и немножко `pandas` (но весь пандовый код уже записан за вас)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe57d0-d301-478e-b62c-461c7a6d7429",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c42584-2fad-4d45-b10c-6430111ac741",
   "metadata": {},
   "source": [
    "Загрузите файлы в питон. (**Совет**: Удобнее всего это сделать с помощью словаря, в котором ключами являются названия файлов, а значениями — их тексты. Это поможет автоматизировать загрузку и обработку текстов.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227900c-03c0-4d22-b7ff-9e8ed5af31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    \"sem14-gorkiy-zhizn_klima_samgina\",\n",
    "    \"sem14-pushkin-istoria_pugacheva\",\n",
    "    \"sem14-tolstoy-voyna_i_mir\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822c720-2847-4a2d-bc10-fe1e660d2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт модулей и загрузка файлов\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ef353-e416-4195-bebc-cf5e30aa229b",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8180c77-91ad-4f31-8d66-63d1c84649e8",
   "metadata": {},
   "source": [
    "**Напишите функцию `lemmatize_text()`**, которая будет:\n",
    "- принимать на вход (1) текст, (2) название текста\n",
    "- токенизировать текст\n",
    "  - отсеивать токены, которые есть в списке стоп-слов (стоп-слова можно взять из `nltk.corpus`)\n",
    "  - отсеивать токены, которые морфологический анализатор `pymorphy3` определил как знаки пунктуации (у них в разборе будет тэг `\"PNCT\"`)\n",
    "- лемматизировать все токены\n",
    "  - подсчитывать размер текста и печатать на экране название текста и кол-во токенов\n",
    "- «склеивать» все токены в единую большую строку (через пробел)\n",
    "  - («склеивание» нужно, потому что `TfidfVectorizer` ожидает, что мы подадим в него строку с текстом, а не список токенов)\n",
    "- возвращать эту строку\n",
    "\n",
    "**Примените эту функцию к корпусу текстов** и сохраните результат. (Лемматизация такого объёма текстов может занимать довольно долго, имейте это в виду. Это нормально!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b47e7a-0dc8-4e52-b25a-f3561ecec73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция lemmatize_text()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c731b1ce-65dd-4403-b2bd-dd5cc6e1b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# её применение к корпусу\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37c4ea-f55a-4001-9d97-cb311f4cbbb3",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893b730-0963-4ea7-92d3-12f25c526de7",
   "metadata": {},
   "source": [
    "Теперь поэкспериментируем с векторизацией. **Создадим два объекта `TfidfVectorizer`** с разными настройками. Один из них будет делать обычный «мешок слов», то есть *bag of words*, или **BOW** (просто считать количество вхождений слов), а второй будет делать настоящий **TF-IDF**. Ну а затем мы сравним результаты их работы на нашем корпусе.\n",
    "\n",
    "Для этого выставьте при создании векторизаторов такие настройки:\n",
    "- *в первом случае*: IDF не использовать (`use_idf=False`), нормализацию не проводить (`norm=None`)\n",
    "- *во втором случае*: стандартные настройки (без подачи аргументов `use_idf` и `norm`) $→$ векторизатор будет проводить нормализацию и считать IDF\n",
    "\n",
    "Функцию для токенизации указывать необязательно.\n",
    "\n",
    "> (Так как в нашем корпусе всего три текста, вычисление IDF не имеет большого смысла и не будет значимо менять значения векторов. IDF становится по-настоящему важным на больших корпусах и небольших текстах. Но мы всё равно попробуем использовать его — во втором токенизаторе — просто для привычки.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12318045-057c-46ef-aafa-bf18534120ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первый векторизатор\n",
    "BOW_vectorizer = \n",
    "\n",
    "# второй векторизатор\n",
    "TFIDF_vectorizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734bf8e-3ceb-4be4-be29-8da8a4133b5e",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf928e-bb49-4883-a3b7-c519fa00d105",
   "metadata": {},
   "source": [
    "**Допишите функцию `make_vectors()`**, которая должна:\n",
    "- принимать на вход объект-векторизатор `vectorizer`, список текстов `texts` и список названий текстов `text_titles`\n",
    "- векторизовать тексты в корпусе и сохранять матрицу в переменную `vector_matrix`\n",
    "- вынимать из объекта-векторизатора «словарь» корпуса (список всех слов) и сохранять его в переменную `corpus_vocabulary`\n",
    "- создавать из матрицы векторов таблицу-датафрейм и возвращать её (***обратите внимание, этот шаг уже написан за вас!***)\n",
    "\n",
    "(*Подсказка*. Весь нужный код есть в тетрадке с семинара.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f72173-bd48-400f-8d36-d579ba11c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vectors(vectorizer, texts, text_titles):\n",
    "\n",
    "    # создаём матрицу векторов\n",
    "    vector_matrix = \n",
    "\n",
    "    # вынимаем «словарь» корпуса\n",
    "    corpus_vocabulary = \n",
    "\n",
    "    # создаём из матрицы красивую таблицу\n",
    "    # (этот шаг уже написан за вас ↓)\n",
    "    vector_table = pd.DataFrame(vector_matrix.toarray(),\n",
    "                                columns=corpus_vocabulary,   # названия столбцов — слова\n",
    "                                index=text_titles)           # названия строк — тексты\n",
    "    return vector_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04019a72-d78d-4217-afdd-c7fe67cc8d7f",
   "metadata": {},
   "source": [
    "С помощью функции `make_vectors()` и двух векторизаторов **получите вектора для корпуса двумя способами** — с помощью «мешка слов» и с помощью TF-IDF. В результате у вас должно получиться две таблицы с векторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba37941-dce4-496b-8892-78dcb0ff3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизация корпуса\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45335ab9-9a55-4bca-8b96-ead16c63b147",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdac844-50b3-4120-86e0-d184b7c8dce8",
   "metadata": {},
   "source": [
    "#### Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe731c-15f6-4649-a36b-122a51c7e5d6",
   "metadata": {},
   "source": [
    "Найдите в таблице с векторами TF-IDF нужные значения для некоторых ключевых слов, и с помощью этих значений **попробуйте ответить на вопросы ниже**. В рамках этого задания будем считать, что ключевое слово важно для текста, если его значение TF-IDF больше $0,01$. *При поиске по ключевым словам помните, что все слова в таблице с векторами были лемматизированы и переведены в строчный регистр!*\n",
    "\n",
    "- Есть ли среди этих текстов такие, в которых важной темой является **война**?\n",
    "- Есть ли среди этих текстов такие, в которых одной из локаций является **гимназия**?\n",
    "- Есть ли среди этих текстов такие, в которых важными действующими лицами являются персонажи-**казаки**?\n",
    "- Есть ли среди этих текстов такие, действие которых разворачивается в **Москве**?\n",
    "- Есть ли среди этих текстов такие, действие которых разворачивается на берегах **Волги**?\n",
    "\n",
    "> Воспользуйтесь ячейкой ниже, чтобы поискать в таблице нужные ключевые слова. В этой же ячейке (или в отдельной) запишите свои ответы и очень кратко их поясните."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ec862-5769-48ff-8d2f-ffb055543b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваше решение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bf5ae-3645-44f8-90b1-15d2d4e16c9f",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c25a0b-6b70-4df7-99e8-013fd3f3cb09",
   "metadata": {},
   "source": [
    "#### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1311c70-a473-489a-9764-0410f0bfdc99",
   "metadata": {},
   "source": [
    "**Сравните две получившиеся векторизации** (с «мешком слов» и с TF-IDF) **по тому, что они сообщают о слове «любовь»**. В каком из текстов это слово встречается большее число раз (согласно «мешку слов»)? А для какого из текстов это слово важнее, чем для других текстов (согласно TF-IDF)? Попробуйте объяснить разницу в «показаниях» этих двух метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e54a2b-27dd-483d-b395-89e01ee0b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваше решение\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
